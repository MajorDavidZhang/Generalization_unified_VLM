{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:00, 10804.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation_accuracy:0.3333333333333333\n",
      "time_accuracy:0.051587301587301584\n",
      "color_accuracy:0.9523809523809523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:00, 5660.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation_accuracy:0.5242200328407225\n",
      "time_accuracy:0.027777777777777776\n",
      "color_accuracy:0.7261904761904762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:00, 10589.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation_accuracy:0.7830459770114943\n",
      "time_accuracy:0.8333333333333334\n",
      "color_accuracy:0.8690476190476191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:00, 5518.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation_accuracy:0.9113300492610837\n",
      "time_accuracy:1.0\n",
      "color_accuracy:0.9761904761904762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "138it [00:00, 5153.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation_accuracy:0.9206349206349206\n",
      "time_accuracy:1.0\n",
      "color_accuracy:0.9473684210526315\n",
      "tensor([0.3333, 0.5242, 0.7830, 0.9113, 0.9206])\n",
      "tensor([0.0516, 0.0278, 0.8333, 1.0000, 1.0000])\n",
      "tensor([0.9524, 0.7262, 0.8690, 0.9762, 0.9474])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import torch\n",
    "\n",
    "# 定义 color_mapping\n",
    "color_mapping = {\n",
    "    'red': [0.1, 0.15],\n",
    "    'green': [0.15, 0.3],\n",
    "    'blue': [0.3, 0.45],\n",
    "    'yellow': [0.45, 0.6],\n",
    "    'orange': [0.6, 0.75],\n",
    "    'purple': [0.75, 0.9]\n",
    "}\n",
    "\n",
    "# 提取所有颜色\n",
    "colors = color_mapping.keys()\n",
    "\n",
    "# 检查颜色是否存在于字符串中\n",
    "def find_colors_in_string(input_string):\n",
    "    found_colors = [color for color in colors if color in input_string]\n",
    "    return found_colors\n",
    "\n",
    "\n",
    "def map_to_color(pixel):\n",
    "    if pixel<0.1:\n",
    "        return 'black'\n",
    "    elif 0.1<=pixel<0.15:\n",
    "        return 'red'\n",
    "    elif 0.15<=pixel<0.3:\n",
    "        return 'green'\n",
    "    elif 0.3<=pixel<0.45:\n",
    "        return 'blue'\n",
    "    elif 0.45<=pixel<0.6:\n",
    "        return 'yellow'\n",
    "    elif 0.6<=pixel<0.75:\n",
    "        return 'orange'\n",
    "    elif 0.75<=pixel<=0.9:\n",
    "        return 'purple'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "def compare_img(gen_img,gt_img):\n",
    "    correct_pixel=0\n",
    "    incorrect_pixel=0\n",
    "    for i in range(len(gen_img)):\n",
    "        for j in range(len(gen_img[i])):\n",
    "            if map_to_color(gen_img[i][j])!=map_to_color(gt_img[i][j]):\n",
    "                incorrect_pixel+=1\n",
    "            else:\n",
    "                correct_pixel+=1\n",
    "    return correct_pixel,incorrect_pixel\n",
    "\n",
    "acc=[]\n",
    "answer_list=[i*78 for i in range(1,6)]\n",
    "for answer in answer_list:\n",
    "    #data_path=f'/datadrive_a/jihai/LLaVA/answer/answer-llava-v1.5-7b-mix-u-odd-{i}.jsonl'\n",
    "    data_path=f'./answer-llava-v1.5-7b-segment-digit-lora-{answer}.jsonl'\n",
    "    correct_piexl=0\n",
    "    incorrect_pixel=0\n",
    "    correct_time=0\n",
    "    incorrect_time=0\n",
    "    correct_color=0\n",
    "    incorrect_color=0\n",
    "    count=0\n",
    "    bound=5\n",
    "    with open (data_path, \"r\") as f:\n",
    "        for line in tqdm(f):\n",
    "            # count+=1\n",
    "            # if count<bound:\n",
    "            #     continue\n",
    "            # if count>bound:\n",
    "            #     break\n",
    "            json_obj = json.loads(line.strip())\n",
    "            #print(json_obj)\n",
    "            # generation:\n",
    "            if '<image>' in json_obj['groun_truth']:\n",
    "                gt_img=json_obj['groun_truth_img_tensor']\n",
    "                gen_img=json_obj['output_img_tensor']\n",
    "                if gen_img !=None:\n",
    "                    correct,incorrect=compare_img(gen_img,gt_img)\n",
    "                    correct_piexl+=correct\n",
    "                    incorrect_pixel+=incorrect\n",
    "                else:\n",
    "                    incorrect_pixel+=6*7\n",
    "            else:\n",
    "                gt_time=re.findall(r'\\d+',json_obj['groun_truth'])\n",
    "                gen_time=re.findall(r'\\d+',json_obj['answer'])\n",
    "                if len(gen_time)!=0:\n",
    "                    for i in range(len(gt_time)):\n",
    "                        if i<len(gen_time) and gt_time[i]==gen_time[i]:\n",
    "                            correct_time+=1\n",
    "                        else:\n",
    "                            incorrect_time+=1\n",
    "                else:\n",
    "                    incorrect_time+=3\n",
    "                gt_color=find_colors_in_string(json_obj['groun_truth'])\n",
    "                gen_color=find_colors_in_string(json_obj['answer'])\n",
    "                if len(gen_color)!=0 and gt_color[0]==gen_color[0]:\n",
    "                    correct_color+=1\n",
    "                else:\n",
    "                    incorrect_color+=1\n",
    "    acc.append([correct_piexl/(correct_piexl+incorrect_pixel),correct_time/(correct_time+incorrect_time),correct_color/(correct_color+incorrect_color)])\n",
    "    print(f\"generation_accuracy:{correct_piexl/(correct_piexl+incorrect_pixel)}\")\n",
    "    print(f\"time_accuracy:{correct_time/(correct_time+incorrect_time)}\")\n",
    "    print(f\"color_accuracy:{correct_color/(correct_color+incorrect_color)}\")\n",
    "acc=torch.Tensor(acc)\n",
    "acc=acc.permute(1,0)\n",
    "print(acc[0])\n",
    "print(acc[1])\n",
    "print(acc[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:14:20\n"
     ]
    }
   ],
   "source": [
    "print(':'.join(gt_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[4., 9., 5., 4.],\n",
      "          [2., 1., 4., 2.],\n",
      "          [6., 6., 6., 7.],\n",
      "          [5., 2., 1., 2.]]]])\n"
     ]
    }
   ],
   "source": [
    "from sklearn import kernel_approximation\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "padded_input=torch.Tensor([[0., 0., 0., 1., 0., 0.],\n",
    "        [1., 0., 1., 1., 1., 0.],\n",
    "        [0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 1., 1., 0., 0.],\n",
    "        [0., 0., 0., 1., 0., 0.],\n",
    "        [1., 0., 1., 1., 1., 0.]]).unsqueeze(0).unsqueeze(0)\n",
    "padded_input=torch.Tensor([[0., 1., 1., 1., 0., 1.],\n",
    "        [0., 0., 0., 0., 0., 0.],\n",
    "        [0., 1., 1., 0., 0., 1.],\n",
    "        [0., 0., 1., 0., 0., 0.],\n",
    "        [0., 1., 1., 1., 0., 1.],\n",
    "        [0., 0., 0., 0., 0., 0.]]).unsqueeze(0).unsqueeze(0)\n",
    "kernel=torch.Tensor([[1, 0, 3],\n",
    "    [0, 0, 2],\n",
    "    [4, 1, 0]]).unsqueeze(0).unsqueeze(0) \n",
    "output = F.conv2d(padded_input, kernel, stride=1)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
