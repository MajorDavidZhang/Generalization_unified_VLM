{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "understanding_templates = [\n",
    "    \"<image>\\nWhat is the time and its color in the image?\",\n",
    "    \"<image>\\nCan you tell me the time displayed on the clock and its color?\",\n",
    "    \"<image>\\nPlease identify the time and the color shown in the display.\",\n",
    "    \"<image>\\nWhat time is it, and what is the color of the numbers?\",\n",
    "    \"<image>\\nProvide the time and the corresponding color for the digits shown.\",\n",
    "    \"<image>\\nThe image shows a clock. What is the time, and what is its color?\",\n",
    "    \"<image>\\nTell me the time and the digits' color in the picture.\",\n",
    "    \"<image>\\nFrom the display, what is the time, and what color are the digits?\",\n",
    "    \"<image>\\nWhat does the display show in terms of time and color?\",\n",
    "    \"<image>\\nIdentify the time and the color of the display in the image.\",\n",
    "]\n",
    "\n",
    "understanding_answers = [\n",
    "    \"The time is {time} and the color is {color}.\",\n",
    "    \"{time} is the time shown, and the digits are in {color}.\",\n",
    "    \"It is {time}, and the color of the display is {color}.\",\n",
    "    \"The display shows {time}, and its color is {color}.\",\n",
    "    \"{time} is what the display reads, with a {color} color.\",\n",
    "    \"The clock says {time}, and the numbers are {color}.\",\n",
    "    \"{color} is the color, and the time is {time}.\",\n",
    "    \"The digits are in {color}, and the time is {time}.\",\n",
    "    \"You can see {time} in the image, and the color is {color}.\",\n",
    "    \"The image shows a display reading {time} in {color} color.\",\n",
    "]\n",
    "\n",
    "generation_templates = [\n",
    "    \"Please show me an image of {time} with {color} digits.\",\n",
    "    \"Can you generate an image displaying {time} in {color}?\",\n",
    "    \"Create a clock image that reads {time} with a {color} display.\",\n",
    "    \"Generate an image showing {time} using {color} digits.\",\n",
    "    \"I want to see an image of {time} with numbers in {color}.\",\n",
    "    \"Make a display image with the time {time} in {color}.\",\n",
    "    \"Draw a clock reading {time} with digits in {color}.\",\n",
    "    \"Show me a time display that says {time} in {color}.\",\n",
    "    \"Produce an image of {time} where the numbers are {color}.\",\n",
    "    \"Create a visual representation of {time} in {color}.\",\n",
    "]\n",
    "\n",
    "generation_answers = [\n",
    "    \"This is the image of {time} with {color} digits. \\n<image>\",\n",
    "    \"Here is the display showing {time} in {color}. \\n<image>\",\n",
    "    \"An image of {time} with numbers in {color} is shown. \\n<image>\",\n",
    "    \"This is the requested image: {time} in {color}. \\n<image>\",\n",
    "    \"Here you go: a clock showing {time} in {color} digits. \\n<image>\",\n",
    "    \"Generated an image with {time} in {color} display. \\n<image>\",\n",
    "    \"This image shows {time} with digits in {color}. \\n<image>\",\n",
    "    \"Displayed {time} with the requested {color} digits. \\n<image>\",\n",
    "    \"The image is created: {time} in {color}. \\n<image>\",\n",
    "    \"The visual shows {time} numbers in {color} digits. \\n<image>\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1.],\n",
      "         [1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "b=torch.zeros(2,3)\n",
    "a=torch.ones(1,b.shape[0],b.shape[1],dtype=b.dtype,device=b.device)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Seven-segment display representation for digits 0-9\n",
    "seven_segment_encoding = {\n",
    "    '0': [1, 1, 1, 1, 1, 1, 0],\n",
    "    '1': [0, 1, 1, 0, 0, 0, 0],\n",
    "    '2': [1, 1, 0, 1, 1, 0, 1],\n",
    "    '3': [1, 1, 1, 1, 0, 0, 1],\n",
    "    '4': [0, 1, 1, 0, 0, 1, 1],\n",
    "    '5': [1, 0, 1, 1, 0, 1, 1],\n",
    "    '6': [1, 0, 1, 1, 1, 1, 1],\n",
    "    '7': [1, 1, 1, 0, 0, 0, 0],\n",
    "    '8': [1, 1, 1, 1, 1, 1, 1],\n",
    "    '9': [1, 1, 1, 1, 0, 1, 1],\n",
    "}\n",
    "\n",
    "color_mapping={'red':[0.1,0.15],'green':[0.15,0.3],'blue':[0.3,0.45],'yellow':[0.45,0.6],'orange':[0.6,0.75],'purple':[0.75,0.9]}\n",
    "\n",
    "# Function to convert time (HH:MM:SS) to numpy array\n",
    "def time_to_tensor(time_str,color):\n",
    "    time_digits = time_str.replace(':', '')  # Remove colon\n",
    "    tensor = np.zeros((6, 7), dtype=int)  # Create a tensor of shape (6, 7)\n",
    "    \n",
    "    for i, digit in enumerate(time_digits):\n",
    "        if digit in seven_segment_encoding:\n",
    "            tensor[i] = np.array(seven_segment_encoding[digit])  # Assign corresponding encoding\n",
    "    color=color_mapping[color]\n",
    "    color=np.random.uniform(color[0], color[1])\n",
    "\n",
    "    return torch.Tensor(tensor)*color\n",
    "\n",
    "# Example: Convert time \"13:25:14\" to tensor\n",
    "# time_str = \"11:25:30\"\n",
    "# color='red'\n",
    "# tensor_representation = time_to_tensor(time_str,color)\n",
    "# print(tensor_representation)\n",
    "\n",
    "def generate_random_time_and_color(parity=0):\n",
    "    def generate_number(max_value, parity):\n",
    "        \"\"\"根据奇偶性生成数字\"\"\"\n",
    "        if parity == 1:  # 只能是奇数\n",
    "            return random.choice([i for i in range(0, max_value + 1) if i % 2 == 1])\n",
    "        elif parity == 2:  # 只能是偶数\n",
    "            return random.choice([i for i in range(0, max_value + 1) if i % 2 == 0])\n",
    "        else:  # 随机生成\n",
    "            return random.randint(0, max_value)\n",
    "    hour = generate_number(23, parity)\n",
    "    minute = generate_number(59, parity)\n",
    "    second = generate_number(59, parity)\n",
    "    time_str = f\"{hour:02}:{minute:02}:{second:02}\"\n",
    "    color = random.choice(list(color_mapping.keys()))\n",
    "    return time_str, color\n",
    "\n",
    "# Function to generate samples\n",
    "def generate_samples(num_samples=100):\n",
    "    samples = []\n",
    "    for _ in range(num_samples):\n",
    "        # time_str, color = generate_random_time_and_color()\n",
    "        # tensor = time_to_tensor(time_str, color)\n",
    "\n",
    "        # Randomly select a task: understanding or generation\n",
    "        task_type = random.choice([\"understanding\", \"generation\"])\n",
    "\n",
    "        if task_type == \"understanding\":\n",
    "            time_str, color = generate_random_time_and_color(2)\n",
    "            tensor = time_to_tensor(time_str, color)\n",
    "            question = random.choice(understanding_templates).format(time=time_str, color=color)\n",
    "            answer = random.choice(understanding_answers).format(time=time_str, color=color)\n",
    "        else:\n",
    "            time_str, color = generate_random_time_and_color()\n",
    "            tensor = time_to_tensor(time_str, color)\n",
    "            question = random.choice(generation_templates).format(time=time_str, color=color)\n",
    "            answer = random.choice(generation_answers).format(time=time_str, color=color)\n",
    "\n",
    "        samples.append({\n",
    "            \"task\": task_type,\n",
    "            'conversations': [{'from':'human','value':question},{'from':'gpt','value':answer}],\n",
    "            \"tensor\": tensor.tolist(),  # Save the tensor representation\n",
    "        })\n",
    "\n",
    "    return samples\n",
    "\n",
    "def generate_samples_for_inverse_understanding(num_samples=100):\n",
    "    samples = []\n",
    "    for i in range(num_samples//2):\n",
    "        # time_str, color = generate_random_time_and_color()\n",
    "        # tensor = time_to_tensor(time_str, color)\n",
    "\n",
    "        # Randomly select a task: understanding or generation\n",
    "        task_type = \"generation\"\n",
    "        time_str, color = generate_random_time_and_color()\n",
    "        tensor = time_to_tensor(time_str, color)\n",
    "        question = random.choice(generation_templates).format(time=time_str, color=color)\n",
    "        answer = random.choice(generation_answers).format(time=time_str, color=color)\n",
    "\n",
    "        samples.append({\n",
    "            \"task\": task_type,\n",
    "            'conversations': [{'from':'human','value':question},{'from':'gpt','value':answer}],\n",
    "            \"tensor\": tensor.tolist(),  # Save the tensor representation\n",
    "        })\n",
    "\n",
    "        task_type = \"understanding\"\n",
    "        tensor = time_to_tensor(time_str, color)\n",
    "        question = random.choice(understanding_templates).format(time=time_str, color=color)\n",
    "        answer = random.choice(understanding_answers).format(time=time_str, color=color)\n",
    "        \n",
    "\n",
    "        samples.append({\n",
    "            \"task\": task_type,\n",
    "            'conversations': [{'from':'human','value':question},{'from':'gpt','value':answer}],\n",
    "            \"tensor\": tensor.tolist(),  # Save the tensor representation\n",
    "        })\n",
    "\n",
    "    return samples\n",
    "\n",
    "# Generate 10 samples as an example\n",
    "samples = generate_samples_for_inverse_understanding(200)\n",
    "with open('/datadrive_a/jihai/data/multimodalout/dummy_data_inverse_u_eval.json', \"w\") as f:\n",
    "    json.dump(samples, f, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('23:13:27', 'purple')\n"
     ]
    }
   ],
   "source": [
    "print(generate_random_time_and_color())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(tensor_representation,'./dummy_images/0002.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '000000033471', 'image': 'coco/train2017/000000033471.jpg', 'conversations': [{'from': 'human', 'value': '<image>\\nWhat are the colors of the bus in the image?'}, {'from': 'gpt', 'value': 'The bus in the image is white and red.'}, {'from': 'human', 'value': 'What feature can be seen on the back of the bus?'}, {'from': 'gpt', 'value': 'The back of the bus features an advertisement.'}, {'from': 'human', 'value': 'Is the bus driving down the street or pulled off to the side?'}, {'from': 'gpt', 'value': 'The bus is driving down the street, which is crowded with people and other vehicles.'}]}\n"
     ]
    }
   ],
   "source": [
    "list_data_dict = json.load(open('/datadrive_a/jihai/azure_storage2/vigstandard_data/jihai/sharegpt4v/llava_v1_5_mix665k.json', \"r\"))\n",
    "print(list_data_dict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设 Q 是一个张量\n",
    "Q = torch.randn(4096, 4096)\n",
    "Q, _ = torch.linalg.qr(Q, mode='complete')  # 确保它是正交矩阵\n",
    "torch.save(Q, '/datadrive_a/jihai/LLaVA/scripts/v1_5/checkpoints/Q.pth')  # 保存到指定路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
