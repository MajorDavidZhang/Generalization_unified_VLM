{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jihai/anaconda3/envs/multimodal/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5, 0.5, 0.5]\n",
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "from transformers import SiglipImageProcessor, SiglipVisionModel,SiglipVisionConfig\n",
    "from PIL import Image\n",
    "# vision_tower=SiglipVisionModel.from_pretrained('google/siglip-base-patch16-224',cache_dir='/public_data/jihai/tmp/siglip-base-patch16-224')\n",
    "# print(vision_tower.config.hidden_size)\n",
    "processor=SiglipImageProcessor.from_pretrained('google/siglip-base-patch16-224',cache_dir='/public_data/jihai/tmp/siglip-base-patch16-224')\n",
    "print(processor.image_mean)\n",
    "image = Image.open('/public_data/jihai/data/multimodalout/smart_watch_image_test/0.png').convert('RGB')\n",
    "image = processor.preprocess(image, return_tensors='pt')['pixel_values'][0]\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "class VQImageProcessor:\n",
    "    def __init__(self, input_size):\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((input_size, input_size)),  # 调整尺寸\n",
    "            transforms.ToTensor()                        # 转换为Tensor并自动归一化到[0,1\n",
    "        ])\n",
    "\n",
    "    def preprocess(self, image,return_tensors='pt'):\n",
    "        image = self.transform(image)\n",
    "        image=2.0*image-1.0\n",
    "        # 添加批次维度并返回\n",
    "        image=image.unsqueeze(0)\n",
    "        out={'pixel_values':image}\n",
    "        return out\n",
    "processor=VQImageProcessor(256)\n",
    "image = Image.open('/public_data/jihai/data/multimodalout/smart_watch_image_test/0.png').convert('RGB')\n",
    "image = processor.preprocess(image, return_tensors='pt')['pixel_values'][0]\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vq_model import VQ_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0775, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0838, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.9822,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0584, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.0299, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.9151]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(42)\n",
    "strength=1.1\n",
    "\n",
    "vision_tower_hidden_dim=768\n",
    "vision_tower_name='siglip_'\n",
    "\n",
    "Q=torch.eye(vision_tower_hidden_dim)\n",
    "torch.save(Q, vision_tower_name+str(strength)+'identity_matrix.pt')\n",
    "\n",
    "# 设置缩放因子范围（可以根据需要调整）\n",
    "scale_min, scale_max = 1/strength, 1*strength\n",
    "shear_std=1*strength\n",
    "# 生成两个随机缩放因子\n",
    "scale_factors = torch.rand(vision_tower_hidden_dim) * (scale_max - scale_min) + scale_min  # 范围 [scale_min, scale_max]\n",
    "# 创建一个对角矩阵，缩放因子在对角线上\n",
    "scale_matrix = torch.diag(scale_factors)\n",
    "shear = torch.eye(vision_tower_hidden_dim)\n",
    "# 生成上三角部分的随机值（非对角线元素）\n",
    "upper_triangle = torch.triu(\n",
    "    torch.rand(vision_tower_hidden_dim, vision_tower_hidden_dim) * shear_std,\n",
    "    diagonal=1  # 仅填充严格上三角部分\n",
    ")\n",
    "shear = shear + upper_triangle\n",
    "\n",
    "# 3. 组合缩放和剪切（顺序：先缩放，后剪切）\n",
    "#scale_matrix = shear @ scale_matrix\n",
    "print(scale_matrix)\n",
    "torch.save(scale_matrix, vision_tower_name+str(strength)+'scale_matrix.pt')\n",
    "\n",
    "random_matrix = torch.randn(vision_tower_hidden_dim, vision_tower_hidden_dim)\n",
    "# QR 分解得到正交矩阵 Q\n",
    "rotation_matrix, _ = torch.linalg.qr(random_matrix, mode='complete')\n",
    "torch.save(rotation_matrix, vision_tower_name+str(strength)+'rotation_matrix.pt')\n",
    "\n",
    "translation_matrix=torch.rand(vision_tower_hidden_dim)*0.1*strength\n",
    "torch.save(translation_matrix, vision_tower_name+str(strength)+'translation_matrix.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Affine(nn.Module):\n",
    "    def __init__(self, dim,strength,vision_tower_name):\n",
    "        super(Affine, self).__init__()\n",
    "        \n",
    "        # 生成随机正交矩阵 A（使用 QR 分解）\n",
    "        #random_matrix = torch.randn(dim, dim)\n",
    "        # QR 分解得到正交矩阵 Q\n",
    "        #Q, _ = torch.linalg.qr(random_matrix, mode='complete')  # 使用 torch.linalg.qr\n",
    "        Q= torch.load(f\"{vision_tower_name}_{strength}rotation_matrix.pt\")\n",
    "        S=torch.load(f\"{vision_tower_name}_{strength}scale_matrix.pt\")\n",
    "        Q=torch.matmul(Q,S)\n",
    "        B=torch.load(f\"{vision_tower_name}_{strength}translation_matrix.pt\")\n",
    "        # 将 A 和 b 作为常量属性存储，并确保它们不会被训练\n",
    "        self.register_buffer('A', Q)  # register_buffer 确保 A 不可训练\n",
    "        self.register_buffer('b', B)  # 随机平移向量 b，不可训练\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        # 仿射变换 y = A * x + b\n",
    "        x=x.view(-1, self.A.shape[1])\n",
    "        y=torch.matmul(x,self.A) + self.b\n",
    "        y=y.view(-1, 6, self.A.shape[0])\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "strength=1.1\n",
    "vision_tower_name='siglip'\n",
    "transformation= Affine(768, strength, vision_tower_name)\n",
    "\n",
    "torch.save(transformation.state_dict(), f\"{vision_tower_name}_affine_{strength}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0198, -0.0173, -0.0445,  ...,  0.0265, -0.0079,  0.0561],\n",
      "        [ 0.0374, -0.0910,  0.0089,  ...,  0.0167, -0.0290,  0.0090],\n",
      "        [ 0.0253,  0.0264, -0.0415,  ...,  0.1131, -0.0368, -0.0104],\n",
      "        ...,\n",
      "        [-0.0024, -0.0130, -0.0031,  ...,  0.0099, -0.0239, -0.0692],\n",
      "        [ 0.0059, -0.0197,  0.0795,  ..., -0.0227,  0.0086,  0.0752],\n",
      "        [-0.0174, -0.0026,  0.0415,  ...,  0.0335,  0.0274,  0.0208]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Affine(nn.Module):\n",
    "    def __init__(self, dim,strength,vision_tower_name):\n",
    "        super(Affine, self).__init__()\n",
    "        \n",
    "        # 生成随机正交矩阵 A（使用 QR 分解）\n",
    "        #random_matrix = torch.randn(dim, dim)\n",
    "        # QR 分解得到正交矩阵 Q\n",
    "        #Q, _ = torch.linalg.qr(random_matrix, mode='complete')  # 使用 torch.linalg.qr\n",
    "        # Q= torch.load(f\"{vision_tower_name}_{strength}rotation_matrix.pt\")\n",
    "        # S=torch.load(f\"{vision_tower_name}_{strength}scale_matrix.pt\")\n",
    "        # Q=torch.matmul(Q,S)\n",
    "        # B=torch.load(f\"{vision_tower_name}_{strength}translation_matrix.pt\")\n",
    "        B=torch.zeros(dim)\n",
    "        Q= torch.load(f\"{vision_tower_name}_{strength}rotation_matrix.pt\")\n",
    "        #Q=torch.eye(dim)\n",
    "        print(Q)\n",
    "        # 将 A 和 b 作为常量属性存储，并确保它们不会被训练\n",
    "        self.register_buffer('A', Q)  # register_buffer 确保 A 不可训练\n",
    "        self.register_buffer('b', B)  # 随机平移向量 b，不可训练\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        # 仿射变换 y = A * x + b\n",
    "        x=x.view(-1, self.A.shape[1])\n",
    "        y=torch.matmul(x,self.A) + self.b\n",
    "        y=y.view(-1, 6, self.A.shape[0])\n",
    "        return y\n",
    "    \n",
    "strength=1\n",
    "vision_tower_name='siglip'\n",
    "transformation= Affine(768, strength, vision_tower_name)\n",
    "\n",
    "torch.save(transformation.state_dict(), f\"{vision_tower_name}_affine_rota.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
